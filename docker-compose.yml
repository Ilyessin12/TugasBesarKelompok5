version: '3.8'

services:
  # Dashboard service
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - .:/app
      - /app/node_modules # Hindari menimpa node_modules
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL}
    env_file:
      - .env
    restart: unless-stopped
    container_name: bigdata5-dashboard
    
  # API service
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    env_file:
      - .env
    restart: unless-stopped
    container_name: bigdata5-api

  # Transform service
  transform:
    build:
      context: ./transformation
      dockerfile: Dockerfile
    volumes:
      - ./data:/app/data
      - ./hf_cache:/root/.cache/huggingface
    environment:
      - BASE_DOWNLOAD_DIR=/app/data
      - MONGODB_CONNECTION_STRING=${MONGODB_CONNECTION_STRING}
      - MONGODB_DATABASE_NAME=${MONGODB_DATABASE_NAME}
      - COLLECTION_NEWS_SUMMARY_DATA=${COLLECTION_NEWS_SUMMARY_DATA}
      - COLLECTION_FINANCIAL_REPORTS=${COLLECTION_FINANCIAL_REPORTS}
      - NEWS_PART=5
      - CHECKPOINT_INTERVAL=150
      - MONGO_OUTPUT_COLLECTION=Docker_Transformasi_Laporan_Keuangan
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    depends_on:
      - mongodb
    networks:
      - app-network
    container_name: bigdata5-transform
  
  # Mongodb (dibutuhin transform biar bisa konek sama mmongo)
  mongodb:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    networks:
      - app-network
      - scraper-berita-network
      - scraper-finance-network

  # Scraping Berita Service
  berita-scraper:
    build:
      context: ./docker_scaping_berita
      dockerfile: Dockerfile
    container_name: bigdata5-scraping-berita
    environment:
      - PYTHONPATH=/app
    env_file:
      - ./docker_scaping_berita/.env
    volumes:
      - ./docker_scaping_berita/cache:/app/cache
    depends_on:
      - chrome-berita
    networks:
      - scraper-berita-network
    restart: unless-stopped

  # Chrome untuk Scraping Berita
  chrome-berita:
    image: selenium/standalone-chrome:latest
    container_name: selenium-chrome-berita
    ports:
      - "4444:4444"
    environment:
      - SE_NODE_MAX_SESSIONS=10
      - SE_NODE_OVERRIDE_MAX_SESSIONS=true
    volumes:
      - /dev/shm:/dev/shm
    networks:
      - scraper-berita-network
    restart: unless-stopped

  # Scraping Laporan Keuangan Service
  finance-scraper:
    build:
      context: ./docker_scraping_laporan_keuangan(masih error)
      dockerfile: Dockerfile
    container_name: bigdata5-scraping-laporan-keuangan
    environment:
      - PYTHONPATH=/app
    env_file:
      - ./docker_scraping_laporan_keuangan(masih error)/.env
    volumes:
      - ./docker_scraping_laporan_keuangan(masih error)/cache:/app/cache
    depends_on:
      - chrome-finance
    networks:
      - scraper-finance-network
    restart: unless-stopped

  # Chrome untuk Scraping Laporan Keuangan
  chrome-finance:
    image: selenium/standalone-chrome:latest
    container_name: selenium-chrome-finance
    ports:
      - "5555:4444"
    environment:
      - SE_NODE_MAX_SESSIONS=10
      - SE_NODE_OVERRIDE_MAX_SESSIONS=true
    volumes:
      - /dev/shm:/dev/shm
    networks:
      - scraper-finance-network
    restart: unless-stopped

  # Scraping YFinance Service
  yfinance-scraper:
    build:
      context: ./docker_scraping_yfinance
      dockerfile: Dockerfile
    container_name: bigdata5-scraping-yfinance
    environment:
      - PYTHONPATH=/app
    env_file:
      - ./docker_scraping_yfinance/.env
    volumes:
      - ./docker_scraping_yfinance/cache:/app/cache
    restart: unless-stopped
    networks:
      - app-network

# Networks (dibutuhin sama mongo)
networks:
  app-network:
    driver: bridge
  scraper-berita-network:
    driver: bridge
  scraper-finance-network:
    driver: bridge

volumes:
  mongo-data: